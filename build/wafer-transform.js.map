{
  "version": 3,
  "sources": ["../src/utils/data.ts", "../src/scripts/wafer-transform.ts"],
  "sourcesContent": ["\r\n/*\r\n* evaluates if a Marking with the given name exists in the document\r\n*\r\n* @param document - the current Document context\r\n* @param markingName - the name of the Marking to check for\r\n* @returns true if the Marking exists, false otherwise\r\n*/\r\nexport function markingExists(\r\n    document: Spotfire.Dxp.Application.Document,\r\n    markingName: string\r\n): boolean {\r\n    return document.Data.Markings.Contains(markingName);\r\n}\r\n\r\n/*\r\n* gets a Marking with the given name, creating it if it doesn't exist\r\n*\r\n* optionally accepts a `markingColor` to set the color of a created Marking. if\r\n*  the Marking already exists, the color will not be changed. if the Marking\r\n*  doesn't exist, and `markingColor` is not specified, the color will be\r\n*  managed by Spotfire.\r\n*\r\n* @param document - the current Document context\r\n* @param markingName - the name of the Marking to get or create\r\n* @param markingColor - optional. the color to set for the Marking\r\n* @returns the Marking with the given name\r\n*/\r\nexport function getOrCreateMarking(\r\n    document: Spotfire.Dxp.Application.Document,\r\n    markingName: string,\r\n    markingColor?: System.Drawing.Color\r\n): Spotfire.Dxp.Data.DataMarkingSelection {\r\n    if (markingExists(document, markingName)) {\r\n        return document.Data.Markings.Item.get(markingName)!;\r\n    }\r\n    const marking = document.Data.Markings.Add(markingName);\r\n    if (markingColor !== undefined) {\r\n        marking.Color = markingColor;\r\n    }\r\n    return marking;\r\n}\r\n\r\n/*\r\n* creates a new DataTable or replaces an existing one with a \"fresh\" copy of sourceTable\r\n*\r\n* @param document - Spotfire Document context\r\n* @param tableName - the name of the table to create\r\n* @param sourceTable - the DataTable to copy from\r\n* @returns the new table\r\n*/\r\nexport function createOrReplaceDataTable(\r\n    document: Spotfire.Dxp.Application.Document,\r\n    tableName: string,\r\n    sourceTable: Spotfire.Dxp.Data.DataSource\r\n): Spotfire.Dxp.Data.DataTable {\r\n    if (document.Data.Tables.Contains(tableName)) {\r\n        // safe to use ! here since we know the table exists\r\n        const existingTable = document.Data.Tables.Item.get(tableName)!;\r\n        document.Data.Tables.Remove(existingTable);\r\n    }\r\n    const newTable = document.Data.Tables.Add(tableName, sourceTable);\r\n    return newTable;\r\n}\r\n\r\n/*\r\n* tries to get a column by name from a data table, throws an error if it doesn't exist\r\n*\r\n* @param dataTable - the data table to search\r\n* @param columnName - the name of the column to find\r\n* @returns the column if it exists\r\n*/\r\nexport function getColumn(\r\n    dataTable: Spotfire.Dxp.Data.DataTable,\r\n    columnName: string\r\n): Spotfire.Dxp.Data.DataColumn {\r\n    const col = OutParam.create(Spotfire.Dxp.Data.DataColumn);\r\n    if (!dataTable.Columns.TryGetValue(columnName, col.out))\r\n        throw new Error(`Cannot find column '${columnName}' in table '${dataTable.Name}'.`);\r\n    return col;\r\n}", "import { getColumn, createOrReplaceDataTable } from \"../utils/data\";\r\n\r\nconst { DataColumnSignature, AddColumnsSettings, JoinType, DataFlowBuilder, \r\n    DataSourcePromptMode, DataType, DataRowReaderColumn } = Spotfire.Dxp.Data;\r\nconst { PivotTransformation, UnpivotTransformation, ReplaceValuesTransformation,\r\n    AddCalculatedColumnTransformation, ColumnAggregation } = Spotfire.Dxp.Data.Transformations;\r\nconst { DataTableDataSource } = Spotfire.Dxp.Data.Import;\r\nconst { Dictionary } = System.Collections.Generic;\r\n\r\n\r\n// result naming expressions for pivot and transformations\r\nconst STEP1_RESULTNAMINGEXPRESSION = \"%V.%C\";\r\nconst STEP5_RESULTNAMINGEXPRESSION = \"%C\";\r\n\r\n// default values for the wafer transform\r\n// storing them as constants because it's too cumbersome to input column names in the current UI\r\nconst IDENTITY_COLUMNS = \"Wafer,Bin,Lot\";\r\nconst COLUMN_TITLES = \"Circle,Segment,Mask\";\r\nconst COLUMN_VALUES = \"CirclePct,SegmentPct,MaskPct\";\r\nconst AGGREGATION = \"Avg\";\r\nconst OUTPUT_TABLE_NAME = \"Zone Profiles\";\r\n\r\n\r\n/*\r\n* zips two arrays together\r\n*\r\n* @param arr1 - the first array\r\n* @param arr2 - the second array\r\n* @returns an array of arrays where each sub-array contains the corresponding elements from the input arrays\r\n*/\r\nfunction zip(arr1: any[], arr2: any[]): any[] {\r\n    return arr1.map((k, i) => [k, arr2[i]]);\r\n}\r\n\r\n/*\r\n* converts a csv string of column names to an array of DataColumns\r\n*\r\n* @param dataTable - the data table to search\r\n* @param columnNameCsv - a csv string of column names to find\r\n* @returns an array of columns\r\n*/\r\nfunction getColumnsFromCsv(\r\n    dataTable: Spotfire.Dxp.Data.DataTable,\r\n    columnNameCsv: string\r\n): Spotfire.Dxp.Data.DataColumn[] {\r\n    const columnNames = columnNameCsv.split(\",\");\r\n    const results = columnNames.map(columnName => getColumn(dataTable, columnName));\r\n    return results;\r\n}\r\n\r\n/*\r\n* converts an array of DataColumns to an array of DataColumnSignatures\r\n*\r\n* to convert a single DataColumn, use `new DataColumnSignature(dataColumn)`\r\n*\r\n* @param columns - an array of DataColumns to convert\r\n* @returns an array of DataColumnSignatures\r\n*/\r\nfunction convertDataColumnsToDataSignatures(\r\n    columns: Spotfire.Dxp.Data.DataColumn[]\r\n): Spotfire.Dxp.Data.DataColumnSignature[] {\r\n    return columns.map(col => new DataColumnSignature(col));\r\n}\r\n\r\n/*\r\n* applies a series of transformations to a DataTable\r\n*\r\n* @param importContext - the ImportContext to use. this is typically `application.ImportContext`\r\n* @param sourceDataTable - the DataTable to use as a source for the transformations\r\n* @param pkColumns - an array of DataColumns to use as the primary key\r\n* @param titleColumns - an array of DataColumns to use as category columns\r\n* @param valueColumns - an array of DataColumns to aggregate\r\n* @param targetMeasure - the aggregation method to use\r\n* @returns void\r\n*/\r\nfunction applyTransformSeries(\r\n    importContext: Spotfire.Dxp.Data.Import.ImportContext,\r\n    dataSource: Spotfire.Dxp.Data.DataSource,\r\n    pkColumns: Spotfire.Dxp.Data.DataColumn[],\r\n    titleColumns: Spotfire.Dxp.Data.DataColumn[],\r\n    //valueColumns: Spotfire.Dxp.Data.DataColumn[],\r\n    targetMeasure: string,\r\n): Spotfire.Dxp.Data.DataSource {\r\n\r\n    // since we are creating a \"virtual\" instance of baseDataTable for each iteration, we need to\r\n    //  use a DataFlowBuilder to build the transformation series and apply it to a DataSource,\r\n    //  which will ultimately be used in the Add Columns operation\r\n    const dfb = new DataFlowBuilder(dataSource, importContext);\r\n\r\n//1: add percentage column\r\n    const colname = titleColumns[0].Name;\r\n    const colname_pct = `${titleColumns[0].Name}Pct`;\r\n    const step1_addColumns = new AddCalculatedColumnTransformation(\r\n        colname_pct,\r\n        `Count() OVER ([Lot], [Wafer], [${colname}], [Bin]) / Count() OVER ([Lot], [Wafer], [${colname}])`\r\n    )\r\n    dfb.AddTransformation(step1_addColumns);\r\n    let flow = dfb.Build();\r\n    let reader = dfb.Execute(DataSourcePromptMode.None);\r\n\r\n//2: pivot\r\n    // the first Pivot has to be applied immediately or we won't know which columns\r\n    //  to use during the Unpivot step\r\n\r\n    const identityColumnSignatures = convertDataColumnsToDataSignatures(pkColumns);\r\n    const categoryColumnSignatures = convertDataColumnsToDataSignatures(titleColumns);\r\n\r\n    // get the new valueColumn\r\n    const pctColumn = OutParam.create(DataRowReaderColumn);\r\n    reader.Columns.TryGetColumn(colname_pct, pctColumn.out)!;\r\n    const pctColumnSignature = new DataColumnSignature(pctColumn);\r\n\r\n    // we need to convert untyped Javascript arrays to typed arrays that are compatible with .NET\r\n    const identityColumnsList = TypedArray.create(\r\n        DataColumnSignature,\r\n        identityColumnSignatures\r\n    );\r\n    const categoryColumnsList = TypedArray.create(\r\n        DataColumnSignature,\r\n        categoryColumnSignatures\r\n    );\r\n\r\n    // first convert the DataColumnSignatures to ColumnAggregations, then create a TypedArray\r\n    const valueColumnsAgg = new ColumnAggregation(pctColumnSignature, targetMeasure);\r\n\r\n    const step2_pivot = new PivotTransformation();\r\n    step2_pivot.IdentityColumns = identityColumnsList;\r\n    step2_pivot.CategoryColumns = categoryColumnsList;\r\n    step2_pivot.ResultNamingExpression = STEP1_RESULTNAMINGEXPRESSION;\r\n    step2_pivot.ValueColumns = TypedArray.create(\r\n        ColumnAggregation,\r\n        [valueColumnsAgg]\r\n    );\r\n\r\n    dfb.AddTransformation(step2_pivot);\r\n    flow = dfb.Build();\r\n    reader = dfb.Execute(DataSourcePromptMode.None);\r\n\r\n//3: unpivot\r\n\r\n    // generate a list of new columns created by the pivot containing all columns except ones ending with \".0\"\r\n    const newPivotColumns = Array.from(reader.Columns).filter(\r\n        col => col.Name.startsWith(titleColumns[0].Name) && !col.Name.endsWith(\".0\")\r\n    );\r\n\r\n    const step3_unpivot = new UnpivotTransformation();\r\n    step3_unpivot.CategoryName = \"Category\";\r\n    step3_unpivot.CategoryType = DataType.String;\r\n    step3_unpivot.ResultName = \"Value\";\r\n    step3_unpivot.ResultType = DataType.Real;\r\n    step3_unpivot.IdentityColumns = TypedArray.create(\r\n        DataColumnSignature,\r\n        identityColumnSignatures\r\n    );\r\n    step3_unpivot.ValueColumns = TypedArray.create(\r\n        DataColumnSignature,\r\n        newPivotColumns.map(col => new DataColumnSignature(col))\r\n    );\r\n\r\n    dfb.AddTransformation(step3_unpivot);\r\n    flow = dfb.Build();\r\n    reader = dfb.Execute(DataSourcePromptMode.None);\r\n\r\n//4: replace (Empty) with 0\r\n/*\r\nsince the dfb returns a DataFlow, it's not possible to use getColumn to get the new Value column\r\ninstead we need to get the DataType for the \"Value\" column in order to construct a signature\r\n*/\r\n    const valueColumn = OutParam.create(DataRowReaderColumn);\r\n    reader.Columns.TryGetColumn(\"Value\", valueColumn.out)!;\r\n    const valueColumnSignature = new DataColumnSignature(valueColumn);\r\n\r\n    const typedValue = OutParam.create(System.Object);\r\n    if (!valueColumn.DataType.Formatter.TryParse(\"0.0\", typedValue.out))\r\n        throw new Error(\"Cannot parse 0.0 to the correct type for the Value column.\");\r\n\r\n    const step4_replaceValues = new ReplaceValuesTransformation(valueColumnSignature, null, typedValue);\r\n\r\n// using a ReplaceColumnTransformation with `SN()` (SubstituteNull) function as a workaround\r\n//const step3_replaceValues = createReplaceColumnTransform(valueColumnSignature, \"Value\", \"Real(SN([Value], 0))\");\r\n    dfb.AddTransformation(step4_replaceValues);\r\n\r\n//5: add Zone and Area columns\r\n    const step5a_addColumns = new AddCalculatedColumnTransformation(\r\n        \"Zone\",\r\n        \"Split([Category], '.', 1)\"\r\n    );\r\n    const step5b_addColumns = new AddCalculatedColumnTransformation(\r\n        \"Area\",\r\n        \"Split([Category], '.', 2)\"\r\n    );\r\n    dfb.AddTransformation(step5a_addColumns);\r\n    dfb.AddTransformation(step5b_addColumns);\r\n\r\n    flow = dfb.Build();\r\n    reader = dfb.Execute(DataSourcePromptMode.None);\r\n\r\n//6: pivot back\r\n    // get new Zone and Area columns\r\n    const zoneColumn = OutParam.create(DataRowReaderColumn);\r\n    reader.Columns.TryGetColumn(\"Zone\", zoneColumn.out)!\r\n    const zoneColumnSignature = new DataColumnSignature(zoneColumn);\r\n    const areaColumn = OutParam.create(DataRowReaderColumn);\r\n    reader.Columns.TryGetColumn(\"Area\", areaColumn.out)!;\r\n    const areaColumnSignature = new DataColumnSignature(areaColumn);\r\n\r\n    const step6_pivot = new PivotTransformation();\r\n    step6_pivot.IdentityColumns = identityColumnsList;\r\n    step6_pivot.ResultNamingExpression = STEP5_RESULTNAMINGEXPRESSION;\r\n    step6_pivot.CategoryColumns = TypedArray.create(\r\n        DataColumnSignature,\r\n        [zoneColumnSignature, areaColumnSignature]\r\n    );\r\n    step6_pivot.ValueColumns = TypedArray.create(\r\n        ColumnAggregation,\r\n        [new ColumnAggregation(valueColumnSignature, targetMeasure)]\r\n    );\r\n\r\n    dfb.AddTransformation(step6_pivot);\r\n\r\n    flow = dfb.Build();\r\n    reader = dfb.Execute(DataSourcePromptMode.None);\r\n\r\n    return flow;\r\n}\r\n\r\n/*\r\n* applies an AddColumns operation to the operationDataTable.\r\n*\r\n* @param operationDataTable - the DataTable to add columns to\r\n* @param sourceDataTable - the DataTable to copy columns from\r\n* @param pkColumns - an array of DataColumns to use as the primary key for the join\r\n* @param ignoredColumns - an array of DataColumns to ignore when adding columns\r\n*/\r\nfunction applyAddColumns(\r\n    operationDataTable: Spotfire.Dxp.Data.DataTable,\r\n    dataSource: Spotfire.Dxp.Data.DataSource,\r\n    operationPkColumns: Spotfire.Dxp.Data.DataColumn[],\r\n    sourcePkColumns: Spotfire.Dxp.Data.DataColumn[],\r\n    ignoredColumns: Spotfire.Dxp.Data.DataColumnSignature[],\r\n): void {\r\n    const ignoredColumnsList = TypedArray.create(DataColumnSignature, ignoredColumns);\r\n\r\n    // get the columns from the source table based on the names of the primary key columns\r\n    // okay to use ! here since we have already validated\r\n    const operationTablePkColumnSignatures = convertDataColumnsToDataSignatures(operationPkColumns);\r\n    const sourceTablePkColumnSignatures = convertDataColumnsToDataSignatures(sourcePkColumns);\r\n\r\n    // zip the two sets of signatures into tuple pairs\r\n    const columnMapItems = zip(sourceTablePkColumnSignatures, operationTablePkColumnSignatures);\r\n\r\n    // initialize the map and add primary key columns to it in pairs\r\n    const map = new Dictionary(DataColumnSignature, DataColumnSignature);\r\n    columnMapItems.forEach(([sourceCol, operationCol]) => map.Add(sourceCol, operationCol));\r\n\r\n    const settings = new AddColumnsSettings(map, JoinType.LeftOuterJoin, ignoredColumnsList);\r\n    operationDataTable.AddColumns(dataSource, settings);\r\n}\r\n\r\nexport function applyWaferTransform({\r\n    document,\r\n    application,\r\n    baseDataTable,\r\n}: ApplyWaferTransformParameters) {\r\n\r\n    // debug values\r\n    const primaryKeyColumns = IDENTITY_COLUMNS;\r\n    const targetColumnTitles = COLUMN_TITLES;\r\n    const targetColumnValues = COLUMN_VALUES;\r\n    const targetMeasure = AGGREGATION;\r\n    const outputDataTableName = OUTPUT_TABLE_NAME;\r\n\r\n    const baseDataSource = new DataTableDataSource(baseDataTable);\r\n\r\n    // parse columns from csv\r\n    const pkColumns = getColumnsFromCsv(baseDataTable, primaryKeyColumns);\r\n    const titleColumns = getColumnsFromCsv(baseDataTable, targetColumnTitles);\r\n\r\n//TODO: this can probably be squeezed into the loop below\r\n    // the first transformation sequence happens on the new operation data table\r\n    // it's okay to use ! here since we have already validated the inputs\r\n    const firstTitleColumn = titleColumns.shift()!;\r\n\r\n    const newDataSource = applyTransformSeries(\r\n        application.ImportContext,\r\n        baseDataSource,\r\n        pkColumns,\r\n        [firstTitleColumn],\r\n        targetMeasure\r\n    )\r\n\r\n    // create a new data table with the transformations applied\r\n    const operationDataTable = createOrReplaceDataTable(document, outputDataTableName, newDataSource);\r\n\r\n    // apply an AddColumns operation followed by our transformation series for each remaining title column\r\n    for (let i = 0; i < titleColumns.length; i++) {\r\n\r\n        const titleCol = titleColumns[i];\r\n\r\n        const transformedDataTableDataSource = applyTransformSeries(\r\n            application.ImportContext,\r\n            baseDataSource,\r\n            pkColumns,\r\n            [titleCol],\r\n            targetMeasure\r\n        );\r\n\r\n        // based on the names of the provided pk columns, look up the corresponding columns in the\r\n        //  source table based on their name\r\n        const sourcePkColumns = pkColumns.map(col => baseDataTable.Columns.Item.get(col.Name)!);\r\n\r\n        applyAddColumns(\r\n            operationDataTable,\r\n            transformedDataTableDataSource,\r\n            pkColumns,\r\n            sourcePkColumns,\r\n            [] // no columns to ignore\r\n        )\r\n    }\r\n\r\n\r\n}\r\n\r\nRegisterEntryPoint(applyWaferTransform);"],
  "mappings": ";;;AAmDO,WAAS,yBACZ,UACA,WACA,aAC2B;AAC3B,QAAI,SAAS,KAAK,OAAO,SAAS,SAAS,GAAG;AAE1C,YAAM,gBAAgB,SAAS,KAAK,OAAO,KAAK,IAAI,SAAS;AAC7D,eAAS,KAAK,OAAO,OAAO,aAAa;AAAA,IAC7C;AACA,UAAM,WAAW,SAAS,KAAK,OAAO,IAAI,WAAW,WAAW;AAChE,WAAO;AAAA,EACX;AASO,WAAS,UACZ,WACA,YAC4B;AAC5B,UAAM,MAAM,SAAS,OAAO,SAAS,IAAI,KAAK,UAAU;AACxD,QAAI,CAAC,UAAU,QAAQ,YAAY,YAAY,IAAI,GAAG;AAClD,YAAM,IAAI,MAAM,uBAAuB,UAAU,eAAe,UAAU,IAAI,IAAI;AACtF,WAAO;AAAA,EACX;;;AC9EA,MAAM;AAAA,IAAE;AAAA,IAAqB;AAAA,IAAoB;AAAA,IAAU;AAAA,IACvD;AAAA,IAAsB;AAAA,IAAU;AAAA,EAAoB,IAAI,SAAS,IAAI;AACzE,MAAM;AAAA,IAAE;AAAA,IAAqB;AAAA,IAAuB;AAAA,IAChD;AAAA,IAAmC;AAAA,EAAkB,IAAI,SAAS,IAAI,KAAK;AAC/E,MAAM,EAAE,oBAAoB,IAAI,SAAS,IAAI,KAAK;AAClD,MAAM,EAAE,WAAW,IAAI,OAAO,YAAY;AAI1C,MAAM,+BAA+B;AACrC,MAAM,+BAA+B;AAIrC,MAAM,mBAAmB;AACzB,MAAM,gBAAgB;AACtB,MAAM,gBAAgB;AACtB,MAAM,cAAc;AACpB,MAAM,oBAAoB;AAU1B,WAAS,IAAI,MAAa,MAAoB;AAC1C,WAAO,KAAK,IAAI,CAAC,GAAG,MAAM,CAAC,GAAG,KAAK,CAAC,CAAC,CAAC;AAAA,EAC1C;AASA,WAAS,kBACL,WACA,eAC8B;AAC9B,UAAM,cAAc,cAAc,MAAM,GAAG;AAC3C,UAAM,UAAU,YAAY,IAAI,gBAAc,UAAU,WAAW,UAAU,CAAC;AAC9E,WAAO;AAAA,EACX;AAUA,WAAS,mCACL,SACuC;AACvC,WAAO,QAAQ,IAAI,SAAO,IAAI,oBAAoB,GAAG,CAAC;AAAA,EAC1D;AAaA,WAAS,qBACL,eACA,YACA,WACA,cAEA,eAC4B;AAK5B,UAAM,MAAM,IAAI,gBAAgB,YAAY,aAAa;AAGzD,UAAM,UAAU,aAAa,CAAC,EAAE;AAChC,UAAM,cAAc,GAAG,aAAa,CAAC,EAAE,IAAI;AAC3C,UAAM,mBAAmB,IAAI;AAAA,MACzB;AAAA,MACA,kCAAkC,OAAO,8CAA8C,OAAO;AAAA,IAClG;AACA,QAAI,kBAAkB,gBAAgB;AACtC,QAAI,OAAO,IAAI,MAAM;AACrB,QAAI,SAAS,IAAI,QAAQ,qBAAqB,IAAI;AAMlD,UAAM,2BAA2B,mCAAmC,SAAS;AAC7E,UAAM,2BAA2B,mCAAmC,YAAY;AAGhF,UAAM,YAAY,SAAS,OAAO,mBAAmB;AACrD,WAAO,QAAQ,aAAa,aAAa,UAAU,GAAG;AACtD,UAAM,qBAAqB,IAAI,oBAAoB,SAAS;AAG5D,UAAM,sBAAsB,WAAW;AAAA,MACnC;AAAA,MACA;AAAA,IACJ;AACA,UAAM,sBAAsB,WAAW;AAAA,MACnC;AAAA,MACA;AAAA,IACJ;AAGA,UAAM,kBAAkB,IAAI,kBAAkB,oBAAoB,aAAa;AAE/E,UAAM,cAAc,IAAI,oBAAoB;AAC5C,gBAAY,kBAAkB;AAC9B,gBAAY,kBAAkB;AAC9B,gBAAY,yBAAyB;AACrC,gBAAY,eAAe,WAAW;AAAA,MAClC;AAAA,MACA,CAAC,eAAe;AAAA,IACpB;AAEA,QAAI,kBAAkB,WAAW;AACjC,WAAO,IAAI,MAAM;AACjB,aAAS,IAAI,QAAQ,qBAAqB,IAAI;AAK9C,UAAM,kBAAkB,MAAM,KAAK,OAAO,OAAO,EAAE;AAAA,MAC/C,SAAO,IAAI,KAAK,WAAW,aAAa,CAAC,EAAE,IAAI,KAAK,CAAC,IAAI,KAAK,SAAS,IAAI;AAAA,IAC/E;AAEA,UAAM,gBAAgB,IAAI,sBAAsB;AAChD,kBAAc,eAAe;AAC7B,kBAAc,eAAe,SAAS;AACtC,kBAAc,aAAa;AAC3B,kBAAc,aAAa,SAAS;AACpC,kBAAc,kBAAkB,WAAW;AAAA,MACvC;AAAA,MACA;AAAA,IACJ;AACA,kBAAc,eAAe,WAAW;AAAA,MACpC;AAAA,MACA,gBAAgB,IAAI,SAAO,IAAI,oBAAoB,GAAG,CAAC;AAAA,IAC3D;AAEA,QAAI,kBAAkB,aAAa;AACnC,WAAO,IAAI,MAAM;AACjB,aAAS,IAAI,QAAQ,qBAAqB,IAAI;AAO9C,UAAM,cAAc,SAAS,OAAO,mBAAmB;AACvD,WAAO,QAAQ,aAAa,SAAS,YAAY,GAAG;AACpD,UAAM,uBAAuB,IAAI,oBAAoB,WAAW;AAEhE,UAAM,aAAa,SAAS,OAAO,OAAO,MAAM;AAChD,QAAI,CAAC,YAAY,SAAS,UAAU,SAAS,OAAO,WAAW,GAAG;AAC9D,YAAM,IAAI,MAAM,4DAA4D;AAEhF,UAAM,sBAAsB,IAAI,4BAA4B,sBAAsB,MAAM,UAAU;AAIlG,QAAI,kBAAkB,mBAAmB;AAGzC,UAAM,oBAAoB,IAAI;AAAA,MAC1B;AAAA,MACA;AAAA,IACJ;AACA,UAAM,oBAAoB,IAAI;AAAA,MAC1B;AAAA,MACA;AAAA,IACJ;AACA,QAAI,kBAAkB,iBAAiB;AACvC,QAAI,kBAAkB,iBAAiB;AAEvC,WAAO,IAAI,MAAM;AACjB,aAAS,IAAI,QAAQ,qBAAqB,IAAI;AAI9C,UAAM,aAAa,SAAS,OAAO,mBAAmB;AACtD,WAAO,QAAQ,aAAa,QAAQ,WAAW,GAAG;AAClD,UAAM,sBAAsB,IAAI,oBAAoB,UAAU;AAC9D,UAAM,aAAa,SAAS,OAAO,mBAAmB;AACtD,WAAO,QAAQ,aAAa,QAAQ,WAAW,GAAG;AAClD,UAAM,sBAAsB,IAAI,oBAAoB,UAAU;AAE9D,UAAM,cAAc,IAAI,oBAAoB;AAC5C,gBAAY,kBAAkB;AAC9B,gBAAY,yBAAyB;AACrC,gBAAY,kBAAkB,WAAW;AAAA,MACrC;AAAA,MACA,CAAC,qBAAqB,mBAAmB;AAAA,IAC7C;AACA,gBAAY,eAAe,WAAW;AAAA,MAClC;AAAA,MACA,CAAC,IAAI,kBAAkB,sBAAsB,aAAa,CAAC;AAAA,IAC/D;AAEA,QAAI,kBAAkB,WAAW;AAEjC,WAAO,IAAI,MAAM;AACjB,aAAS,IAAI,QAAQ,qBAAqB,IAAI;AAE9C,WAAO;AAAA,EACX;AAUA,WAAS,gBACL,oBACA,YACA,oBACA,iBACA,gBACI;AACJ,UAAM,qBAAqB,WAAW,OAAO,qBAAqB,cAAc;AAIhF,UAAM,mCAAmC,mCAAmC,kBAAkB;AAC9F,UAAM,gCAAgC,mCAAmC,eAAe;AAGxF,UAAM,iBAAiB,IAAI,+BAA+B,gCAAgC;AAG1F,UAAM,MAAM,IAAI,WAAW,qBAAqB,mBAAmB;AACnE,mBAAe,QAAQ,CAAC,CAAC,WAAW,YAAY,MAAM,IAAI,IAAI,WAAW,YAAY,CAAC;AAEtF,UAAM,WAAW,IAAI,mBAAmB,KAAK,SAAS,eAAe,kBAAkB;AACvF,uBAAmB,WAAW,YAAY,QAAQ;AAAA,EACtD;AAEO,WAAS,oBAAoB;AAAA,IAChC;AAAA,IACA;AAAA,IACA;AAAA,EACJ,GAAkC;AAG9B,UAAM,oBAAoB;AAC1B,UAAM,qBAAqB;AAC3B,UAAM,qBAAqB;AAC3B,UAAM,gBAAgB;AACtB,UAAM,sBAAsB;AAE5B,UAAM,iBAAiB,IAAI,oBAAoB,aAAa;AAG5D,UAAM,YAAY,kBAAkB,eAAe,iBAAiB;AACpE,UAAM,eAAe,kBAAkB,eAAe,kBAAkB;AAKxE,UAAM,mBAAmB,aAAa,MAAM;AAE5C,UAAM,gBAAgB;AAAA,MAClB,YAAY;AAAA,MACZ;AAAA,MACA;AAAA,MACA,CAAC,gBAAgB;AAAA,MACjB;AAAA,IACJ;AAGA,UAAM,qBAAqB,yBAAyB,UAAU,qBAAqB,aAAa;AAGhG,aAAS,IAAI,GAAG,IAAI,aAAa,QAAQ,KAAK;AAE1C,YAAM,WAAW,aAAa,CAAC;AAE/B,YAAM,iCAAiC;AAAA,QACnC,YAAY;AAAA,QACZ;AAAA,QACA;AAAA,QACA,CAAC,QAAQ;AAAA,QACT;AAAA,MACJ;AAIA,YAAM,kBAAkB,UAAU,IAAI,SAAO,cAAc,QAAQ,KAAK,IAAI,IAAI,IAAI,CAAE;AAEtF;AAAA,QACI;AAAA,QACA;AAAA,QACA;AAAA,QACA;AAAA,QACA,CAAC;AAAA;AAAA,MACL;AAAA,IACJ;AAAA,EAGJ;AAEA,qBAAmB,mBAAmB;",
  "names": []
}
